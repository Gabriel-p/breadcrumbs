
# Loss functions (mean, median, mode)

Definition of mean, median, and mode as the minimization of loss functions.

### [Modes, Medians and Means: A Unifying Perspective][1]

> Any traditional introductory statistics course will teach students the definitions of modes, medians and means. But, because introductory courses can't assume that students have much mathematical maturity, the close relationship between these three summary statistics can't be made clear. This post tries to remedy that situation by making it clear that all three concepts arise as specific parameterizations of a more general problem.

### [MAP or mean?!][2]

The MAP is expressed as a proper Bayes estimator.

> A frequent matter of debate in Bayesian inversion is the question, which of the two principle point-estimators, the maximum-a-posteriori (MAP) or the conditional mean (CM) estimate is to be preferred.

### [5 Regression Loss Functions All Machine Learners Should Know][3]

> All the algorithms in machine learning rely on minimizing or maximizing a function, which we call “objective function”. The group of functions that are minimized are called “loss functions”. A loss function is a measure of how good a prediction model does in terms of being able to predict the expected outcome. A most commonly used method of finding the minimum point of function is “gradient descent”. Think of loss function like undulating mountain and gradient descent is like sliding down the mountain to reach the bottommost point.



______________________________________________________________
[1]: http://www.johnmyleswhite.com/notebook/2013/03/22/modes-medians-and-means-an-unifying-perspective/
[2]: https://xianblog.wordpress.com/2014/03/05/map-or-mean/
[3]: https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0

